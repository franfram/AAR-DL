{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_stats(df):\n",
    "    # Filter df to only contain acc columns, extract values, flatten, and then \n",
    "    # compute min and max stats\n",
    "    acc_data = df.filter(regex='acc$', axis=1).values.flatten()\n",
    "    stats['acc']['min'] = acc_data.min()\n",
    "    stats['acc']['max'] = acc_data.max()\n",
    "\n",
    "\n",
    "def get_normalization_stats(path):\n",
    "    # Get all paths to segment files files\n",
    "    for dirName, subDirs, fileList in os.walk(path):\n",
    "        if('s01.txt' in fileList):\n",
    "            for file in fileList:\n",
    "                # Read data as csv and keep columns that contain 'acc'\n",
    "                df = read_data(os.path.join(dirName,file))\n",
    "                # compute min and max stats for all data\n",
    "                update_stats(df)\n",
    "    # compute peak to peak (ptp)\n",
    "    stats['acc']['ptp'] = stats['acc']['max'] - stats['acc']['min']\n",
    "            \n",
    "def create_images(data_path, save_path):\n",
    "    \n",
    "    for dirName, subDirs, fileList in os.walk(data_path):\n",
    "        if('segment_1.txt' in fileList):\n",
    "            for file in fileList:\n",
    "                # Create normalized df\n",
    "                df = create_normalized_df(os.path.join(dirName,file))\n",
    "                # Only care about acc right now.\n",
    "                df = df.filter(regex='acc$', axis=1)\n",
    "                # Create image from df, create image name, and save in path\n",
    "                save_image(df, os.path.join(dirName,file), save_path)\n",
    "                \n",
    "            \n",
    "def save_image(df, original_path, save_path):\n",
    "    # Create image name from original_path (e.g., 'eating_sheep_58_segment_101.png')\n",
    "    image_name = create_image_name(original_path)\n",
    "    # Create array of numbers\n",
    "    img_array = df.to_numpy().astype(np.uint8).T\n",
    "    # Create image from array\n",
    "    im = Image.fromarray(img_array)\n",
    "    # Save image\n",
    "    im.save(os.path.join(save_path,image_name))\n",
    "    \n",
    "def create_image_name(original_path):\n",
    "    # Create list with dirName, subDirs, and file \n",
    "    # (e.g., 'b_1, sheep_58, segment_101.txt')\n",
    "    ## .split('/') will give us the list of strings between `/`\n",
    "    ## the [2:] will keep from the 3rd value on. i.e., leave out the '.' and 'datap'\n",
    "    unlabeled_data = original_path.split('/')[2:]\n",
    "    # Replace dirName with predicted_labels_map (e.g., 'b_1' with 'eating')\n",
    "    unlabeled_data[0] = predicted_labels_map[unlabeled_data[0]].replace(' ', '_')\n",
    "    # Join unlabeled_data elements using '_' as separator,  and\n",
    "    # replace '.txt' with '.png'\n",
    "    return'_'.join(unlabeled_data).replace('.txt', '.png')\n",
    "            \n",
    "def read_data(path):\n",
    "    # Read data as csv and keep those columns that contain 'acc'\n",
    "    return pd.read_csv(path, head=0).filter(regex='acc', axis=1)\n",
    "      \n",
    "def create_normalized_df(path):\n",
    "        ## TODO reject column_regex if it is not one of\n",
    "        # acc$, gyro$, mag$, reject\n",
    "        df = read_data(path)\n",
    "        #column_key = regex[:len(regex)-1]\n",
    "        acc_df = df.filter(regex='acc$', axis=1).apply(lambda x: round(255 * (x - stats['acc']['min'])/stats['acc']['ptp']))\n",
    "        \n",
    "        return acc_df\n",
    "         "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
